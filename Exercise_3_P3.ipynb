{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Exercise_3_P3",
      "provenance": [],
      "authorship_tag": "ABX9TyPYhU0CoIlRV1Ze4YdCpnrn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mwojtczak/LogProxy/blob/master/Exercise_3_P3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pc6T0iJh0E0h",
        "colab_type": "code",
        "outputId": "61d582a7-4dc3-4c1b-d0cd-e1a0eb031d3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%run Exercise_2_P3.ipynb"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ERROR:root:File `'Exercise_2_P3.ipynb.py'` not found.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mFNP13GY0Ldt",
        "colab_type": "text"
      },
      "source": [
        "# Validation and cross-validation \n",
        "\n",
        "In this exercise you will implement a validation pipeline. \n",
        "\n",
        "At the end of Exercise 2, you tested your model against the training and test datasets. As you should observe, there's a gap between the results. By validating your model, not only should you be able to anticipate the test time performance, but also have a method to compare different models.\n",
        "\n",
        "Implement the basic validation method, i.e. a random split. Test it with your model from Exercise 2.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9f0DEk50NxN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#######################################################\n",
        "# TODO: Implement the basic validation method,        # \n",
        "# compare MSLE on training, validation, and test sets #\n",
        "#######################################################\n",
        "\n",
        "# print(model)\n",
        "# zmienna model jest zaimportowana z poprzedniego notebooka\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def test_with_districts(df, model, feature_engin=False):\n",
        "    xs, ys = split_df(df, include_district=True)\n",
        "    xs = one_hot_encode_district(xs)\n",
        "    if feature_engin:\n",
        "        xs = add_feature_engineering(xs)\n",
        "    ys_predicted = model.predict(xs)\n",
        "\n",
        "    cost_train = msle(ys, ys_predicted)\n",
        "    print(f'MSLE Test cost = {cost_train} (approx. {sqrt(cost_train):.2f} ^2)')\n",
        "    \n",
        "\n",
        "def train_and_test_with_district(df, df_test, feature_engin=False):\n",
        "    xs, prices = split_df(df, include_district=True)\n",
        "    xs = one_hot_encode_district(xs)\n",
        "    \n",
        "    if feature_engin:\n",
        "        xs = add_feature_engineering(xs)\n",
        "        \n",
        "    x_train, x_validate, y_train, y_validate = train_test_split(xs.values, prices.values, test_size=0.2)\n",
        "    \n",
        "    model = linear_model.SGDClassifier(loss='log', penalty=None, eta0=0.7)\n",
        "    model.fit(x_train, y_train)\n",
        "    ys_predicted = model.predict(x_train)\n",
        "    \n",
        "    cost_train = msle(y_train, ys_predicted)\n",
        "    print(f'MSLE Cost = {cost_train} (approx. {sqrt(cost_train):.2f} ^2)')\n",
        "    \n",
        "    y_validate_predicted = model.predict(x_validate)\n",
        "    cost_validate = msle(y_validate, y_validate_predicted)\n",
        "    print(f'MSLE Train cost = {cost_validate} (approx. {sqrt(cost_validate):.2f} ^2)')\n",
        "    \n",
        "    test_with_districts(df_test, model, True)\n",
        "    return model\n",
        "\n",
        "train_and_test_with_district(df, df_test, True)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYmpt7hE0XrY",
        "colab_type": "text"
      },
      "source": [
        "To make the random split validation reliable, a huge chunk of training data may be needed. To get over this problem, one may apply cross-validaiton.\n",
        "\n",
        "![alt-text](https://chrisjmccormick.files.wordpress.com/2013/07/10_fold_cv.png)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtIEzoOT0ccw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35iEIVeF0euk",
        "colab_type": "text"
      },
      "source": [
        "Let's now implement the method. Make sure that:\n",
        "* number of partitions is a parameter,\n",
        "* the method is not limited to `mieszkania.csv`,\n",
        "* the method is not limited to one specific model.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHOW4Xos0f_r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "####################################\n",
        "# TODO: Implement cross-validation # \n",
        "####################################\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "def prepare_data(df):\n",
        "    xs, ys = split_df(df, include_district=True)\n",
        "    xs = one_hot_encode_district(xs)\n",
        "    xs = add_feature_engineering(xs)\n",
        "    return xs, ys\n",
        "\n",
        "xs, ys = prepare_data(df)\n",
        "xs_test, ys_test = prepare_data(df_test)\n",
        "\n",
        "def get_linear_regression_model():\n",
        "    return linear_model.SGDClassifier(loss='log', penalty=None, eta0=0.7)\n",
        "\n",
        "def cross_validate_model(get_model, xs, ys, partitions=5):\n",
        "    kf = KFold(n_splits=5)\n",
        "    costs = []\n",
        "    for train_index, test_index in kf.split(xs):\n",
        "        X_train, X_test = xs.iloc[train_index], xs.iloc[test_index],\n",
        "        y_train, y_test = ys[train_index], ys[test_index]\n",
        "        val_cost = cross_validate_phase(get_model, X_train, y_train , X_test, y_test)\n",
        "        costs.append(val_cost)\n",
        "    print(f'MSLE Average cost = {sum(costs) / len(costs)} (approx. {sqrt(sum(costs) / len(costs)):.2f} ^2)')\n",
        "        \n",
        "\n",
        "def cross_validate_phase(get_model, x_train, y_train, xs_test, ys_test):\n",
        "    model = get_model()\n",
        "    model.fit(x_train, y_train)\n",
        "    ys_predicted = model.predict(xs_test)\n",
        "    cost_train = msle(ys_test.values, ys_predicted)\n",
        "    print(f'MSLE Cost = {cost_train} (approx. {sqrt(cost_train):.2f} ^2)')\n",
        "    \n",
        "    y_validate_predicted = model.predict(xs_test)\n",
        "    cost_validate = msle(ys_test.values, y_validate_predicted)\n",
        "    print(f'MSLE Train cost = {cost_validate} (approx. {sqrt(cost_validate):.2f} ^2)')\n",
        "    return cost_validate\n",
        "\n",
        "cross_validate_model(get_linear_regression_model, xs, ys, 5)\n",
        "\n",
        "    \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YlW657DX0lUN",
        "colab_type": "text"
      },
      "source": [
        "Recall that sometimes validation may be tricky, e.g. significant class imbalance, having a small number of subjects, geographically clustered instances...\n",
        "\n",
        "What could in theory go wrong here with random, unstratified partitions? Think about potential solutions and investigate the data in order to check whether these problems arise here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51syRAuy0mKi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##############################\n",
        "# TODO: Investigate the data #\n",
        "##############################\n",
        "\n",
        "# Jak powinnismy zdecydowac sie, ile bedzie wynosil learning rate?\n",
        "# Czy należy po prostu kilka-kilkanaście razy wytrenować model dla różnych learning rate i wybrać najlepszy?\n",
        "# A może napisać kod, który będzie badał, jaki lr jest najlepszy - badając z większą granulacją lry, które są bliżej lr o lepszych wynikach?\n",
        "# wydaje się, że kiedy losowo inicjalizuje się wagi (a nie na 0), to może to zaburzać wyniki - niektóre lr będą miały lepszy start\n",
        "# i mogą się nie okazać tak dobre dla mniej szczęśliwych losowań."
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}